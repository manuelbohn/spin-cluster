---
title: "SPIN LLH"
output: html_document
---

```{r setup, include=FALSE}
library(rwebppl)
library(tidyverse)
library(readxl)
library(matrixStats)
```

```{r data}
aoa_ratings <- read_xlsx(path = "data/words_aoa_ratings.xlsx", sheet = 1)%>%
  filter(Word %in% c("carrot","duck","bread","apple","kite","horseshoe","plug","garlic","barrel","eggplant","pawn","papaya"))%>%
  mutate(mean_aoa = as.numeric(Rating.Mean),
         item = Word)%>%
  select(item,mean_aoa)


me_data <- read_csv("data/me.csv")
prior_data <- read_csv("data/novelty.csv")
comb_data <- read_csv("data/combination.csv")%>%
  left_join(aoa_ratings) %>%
  ungroup()%>%
  mutate(item = fct_reorder(factor(item), mean_aoa))

```


```{r}
model <- '

var chain = last(process.argv)

var all_objects = [
  { shape: "novel_object"},
  { shape: "familiar_object"}
]

var labels = ["novel_word","familiar_word"]


var lexicon1 = function(utterance, obj, sem_knowledge){
  utterance.label == "novel_word" ? obj.shape == "novel_object" :
  utterance.label == "familiar_word" ? flip(sem_knowledge) ?
  obj.shape == "familiar_object" :
  flip() ? obj.shape == "familiar_object" : obj.shape == "novel_object" :
  true
}

var lexicon2 = function(utterance, obj, sem_knowledge){
  utterance.label == "novel_word" ? obj.shape == "familiar_object" :
  utterance.label == "familiar_word" ? flip(sem_knowledge) ?
  obj.shape == "familiar_object" :
  flip() ? obj.shape == "familiar_object" : obj.shape == "novel_object" :
  true
}

var lexiconObjects = {
  "novel_word = novel_object": {
    novel_object: "novel_word", familiar_object: "familiar_word"
  },
  "novel_word = familiar_object": {
    novel_object: "familiar_word", familiar_object: "familiar_word"
  },
}

var lexiconObject = {
  "novel_word = novel_object": lexicon1,
  "novel_word = familiar_object" : lexicon2
}

var utterancePrior = function(){ return uniformDraw([ {label: "novel_word"}, {label: "familiar_word"}]) }

var LexiconPrior = Categorical({vs: ["novel_word = novel_object","novel_word = familiar_object" ], ps: [1, 1]})

var foreach = function(fn, lst) {
  var foreach_ = function(i) {
    if (i < lst.length) {
      fn(lst[i]);
      foreach_(i + 1);
    }
  };
  foreach_(0);
};

var logistic = function(x) {1 / (1 + Math.exp(-x))}

var levels = function(df, label){
  return _.uniq(_.map(df, label));
}

//////////////// Inferring parameters //////////////

var meData = dataFromR.meData;
var priorData = dataFromR.priorData;
var combData = dataFromR.combData;

var priorSubjects = levels(priorData, "subid")
var priorSubjectsAges = sort(levels(priorData, "age_month"))

var familiars = levels(meData, "item")
var familiarsAges = sort(levels(meData, "age_month"))

var subjects = levels(meData, "subid")

var combDataAges = sort(levels(combData, "age_month"))

var priorProbs = [.5, .5]

var model  = function(){


  var mixture_slope = uniformDrift({
    a: -2,
    b: 2,
    width: 0.4
  })
  
  var mixture_int = uniformDrift({
    a: -2,
    b: 2,
    width: 0.4
  })


  var mixture = uniformDrift({
    a: 0,
    b: 1,
    width: 0.1
  })

  ////////////// Prior ////////////////////////

  var prior_slope = uniformDrift({
    a: -2,
    b: 2,
    width: 0.4
  })
  var prior_int = uniformDrift({
    a: -2,
    b: 2,
    width: 0.4
  })

  foreach(function(age_month){
    var priorSubjectDataByAge = _.filter(priorData, {age_month: age_month})

    var subj_age = priorSubjectDataByAge[0].age_month

    var priorSubjectDataByAge_correct = _.map(priorSubjectDataByAge, "correct")

    var priorReg = logistic(prior_int + prior_slope * subj_age)
    var prior = [priorReg, 1 - priorReg]

    var modelPredictions = Infer({method: "enumerate", model: function(){
      var obj = sample( Categorical({vs: all_objects, ps: prior}));
      return obj.shape == "novel_object" ? 1 : 0
    }})

    mapData({data: priorSubjectDataByAge_correct}, function(d){
      observe(modelPredictions, d);
    })

  }, priorSubjectsAges)

  //query.add(["parameter","parameters", "prior", "intercept", "NA", "NA"], prior_int)
  //query.add(["parameter","parameters", "prior", "slope", "NA", "NA"], prior_slope)


  //////////////// Semantic knowledge and speaker optimality ////////////////////////

  var speakerOptimalityParameters = {
    intercept: uniformDrift({
      a: -3,
      b: 3,
      width: 0.5
    }),
    slope: uniformDrift({
      a: 0,
      b: 4,
      width: 0.5
    })
  }

  var globalLineParameters = {
    intercept: uniformDrift({
      a: -3,
      b: 3,
      width: 0.5
    }),
    slope: uniformDrift({
      a: 0,
      b: 2,
      width: 0.5
    })
  }

  var itemVariability = {
    intercept: uniformDrift({
      a: 0,
      b: 2,
      width: 0.2
    }),
    slope: uniformDrift({
      a: 0,
      b: 1,
      width: 0.2
    })
  }

  var sampleItemParameters = function(itemName) {
    return [itemName, {
      intercept: gaussianDrift({
        mu: globalLineParameters.intercept,
        sigma: itemVariability.intercept,
        width: 0.5
      }),
      slope: gaussianDrift({
        mu: globalLineParameters.slope,
        sigma: itemVariability.slope,
        width: 0.5
      })
    }]
  }

  var all_item_parameters = _.fromPairs(map(sampleItemParameters, familiars))

  var subject_sigma = uniformDrift({
    a: 0,
    b: 1,
    width: 0.1
  })

  var sampleLinguisticCompetence = function(age) {
    return gaussianDrift({
      mu: age,
      sigma: subject_sigma,
      width: 0.1
    })
  }

  foreach(function(age_month){

    var subjectData_byAge = _.filter(meData, {age_month: age_month})

    var subj_age = subjectData_byAge[0].age_month
    var speakerOptimality = speakerOptimalityParameters.intercept  + speakerOptimalityParameters.slope * subj_age

    foreach(function(item){
      var subjectData_byAgeItem = _.filter(subjectData_byAge, {item: item})
      var subjectDataByAgeItem_correct = _.map(subjectData_byAgeItem, "correct")

      var itemLineParameters = all_item_parameters[item]

      var sem_knowledge = logistic(itemLineParameters.intercept +
        itemLineParameters.slope * subj_age)

        var literalListener = cache(function(utterance){
          Infer({method: "enumerate", model: function(){
            var lexiconName = sample(LexiconPrior);
            var lexicon = lexiconObject[lexiconName];
            var obj = sample( Categorical({vs: all_objects, ps: [.5,.5]}));
            if ("label" in utterance) {
              var truthValue = lexicon(utterance, obj, sem_knowledge);
              condition(truthValue)
            }
            return obj.shape
          }})}, 10000)

          var speaker = cache(function(obj, lexiconName){
            Infer({method: "enumerate", model: function(){
              var utterance = utterancePrior();
              var L0 = literalListener(utterance);
              factor(speakerOptimality * L0.score(obj.shape))
              return utterance
            }})}, 10000)

            var pragmaticListener = function(utterance){
              Infer({method: "enumerate", model: function(){
                var lexiconName = sample(LexiconPrior);
                var obj = sample( Categorical({vs: all_objects, ps: [.5,.5]}));
                var S1 = speaker(obj, lexiconName);
                observe(S1, utterance)
                return obj.shape == "novel_object" ? 1 : 0
              }})}

              var modelPredictions = pragmaticListener({label: "novel_word"})

              mapData({data: subjectDataByAgeItem_correct}, function(d){
                observe(modelPredictions, d)
              })

            }, familiars)

          }, familiarsAges)

          //////////////// Model predictions and combination ////////////////////////

          foreach(function(age_month) {

            var combData_byAge = _.filter(combData, {age_month: age_month})

            var priorReg = logistic(prior_int + prior_slope * age_month)

            var global_sem_knowledge = logistic(globalLineParameters.intercept +
              globalLineParameters.slope * age_month)

              var speakerOptimality = speakerOptimalityParameters.intercept  +
              speakerOptimalityParameters.slope * age_month

              foreach(function(item){

                var itemLineParameters = all_item_parameters[item]
                var item_sem_knowledge = logistic(itemLineParameters.intercept +
                  itemLineParameters.slope * age_month)


                  foreach(function(alignment_condition){

                    var priorComb = (alignment_condition == "congruent") ? [priorReg, 1 - priorReg] : [1 - priorReg, priorReg]
               
                    
                   var combinationData_byAge_byItem_byCondition = _.filter(combData, {
                    age_month: age_month,
                    item: item,
                    alignment: alignment_condition
                    })


                    foreach(function(model_type){

                      var sem_knowledge = (model_type == "global") ? global_sem_knowledge : item_sem_knowledge
                      
                      var priorProbs = (model_type == "flat") ? [0.5, 0.5] : priorComb

                      var literalListener = cache(function(utterance){
                        Infer({method: "enumerate", model: function(){
                          var lexiconName = sample(LexiconPrior);
                          var lexicon = lexiconObject[lexiconName];
                          var obj = sample( Categorical({vs: all_objects, ps: [.5,.5]}));
                          if ("label" in utterance) {
                            var truthValue = lexicon(utterance, obj, sem_knowledge);
                            condition(truthValue)
                          }
                          return obj.shape
                        }})
                      }, 10000)

                      var speaker = cache(function(obj, lexiconName){
                        Infer({method: "enumerate", model: function(){
                          var utterance = utterancePrior();
                          var L0 = literalListener(utterance);
                          factor(speakerOptimality * L0.score(obj.shape))
                          return utterance
                        }})
                      }, 10000)

                      var pragmaticListener = function(utterance){
                        Infer({method: "enumerate", model: function(){
                          var lexiconName = sample(LexiconPrior);
                          var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
                          var S1 = speaker(obj, lexiconName);
                          observe(S1, utterance)
                          return obj.shape == "novel_object" ? 1 : 0
                        }})
                      }

'
```


```{r}
llh <- webppl(
  program_code = paste(model,llh_code, sep='\n'),
  data =list(meData = me_data, priorData = prior_data, combData = comb_data),
  data_var = "dataFromR",
  packages ="webppl-csv",
  chains = 5,
  cores = 5,
  inference_opts = list(method = "MCMC", samples = 10000, burn = 5000, verbose = T)
)

saveRDS(llh, "llh_10000.rds")
```

```{r}
llh <- readRDS("llh_10000.rds")

llh %>%
  mutate(loglike = log(value))%>%
  separate(Parameter,c("type","model"),sep =",")%>%
  group_by(model, Chain)%>%
  summarise(loglike_sample = sum(loglike))%>%
  group_by(model)%>%
  summarize(marginal_likelihood = matrixStats::logSumExp(loglike_sample))
```

For comparison: likelihood from previous run (lesioned and pragmatic model only). This is for prediction, which should basically be the same as we are doing here since we did not updating the parameters. See https://github.com/manuelbohn/spin/blob/master/stats/model_comparison.Rmd line 104 for how we computed the marginal likelihoods previously.

```{r}
readRDS("pred_model_likelihood.rds")
```


